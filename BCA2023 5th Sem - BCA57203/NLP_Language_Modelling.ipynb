{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "735b335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import pos_tag, ne_chunk, bigrams, FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4a3fe80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download required NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('maxent_ne_chunker_tab')\n",
    "nltk.download('words')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17444fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text corpus with clear named entities\n",
    "text = \"The Mars Orbiter Mission (MOM), informally known as Mangalyaan, was launched into Earth orbit on 5 November 2013 by the Indian Space Research Organisation (ISRO) and has entered Mars orbit on 24 September 2014. India thus became the first country to enter Mars orbit on its first attempt. It was completed at a record low cost of $74 million.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76c87731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences:\n",
      " ['The Mars Orbiter Mission (MOM), informally known as Mangalyaan, was launched into Earth orbit on 5 November 2013 by the Indian Space Research Organisation (ISRO) and has entered Mars orbit on 24 September 2014.', 'India thus became the first country to enter Mars orbit on its first attempt.', 'It was completed at a record low cost of $74 million.'] \n",
      "\n",
      "Words:\n",
      " ['the', 'mars', 'orbiter', 'mission', 'mom', 'informally', 'known', 'as', 'mangalyaan', 'was', 'launched', 'into', 'earth', 'orbit', 'on', 'november', 'by', 'the', 'indian', 'space', 'research', 'organisation', 'isro', 'and', 'has', 'entered', 'mars', 'orbit', 'on', 'september', 'india', 'thus', 'became', 'the', 'first', 'country', 'to', 'enter', 'mars', 'orbit', 'on', 'its', 'first', 'attempt', 'it', 'was', 'completed', 'at', 'a', 'record', 'low', 'cost', 'of', 'million'] \n",
      "\n",
      "Stemming:\n",
      " ['the', 'mar', 'orbit', 'mission', 'mom', 'inform', 'known', 'as', 'mangalyaan', 'wa', 'launch', 'into', 'earth', 'orbit', 'on', 'novemb', 'by', 'the', 'indian', 'space', 'research', 'organis', 'isro', 'and', 'ha', 'enter', 'mar', 'orbit', 'on', 'septemb', 'india', 'thu', 'becam', 'the', 'first', 'countri', 'to', 'enter', 'mar', 'orbit', 'on', 'it', 'first', 'attempt', 'it', 'wa', 'complet', 'at', 'a', 'record', 'low', 'cost', 'of', 'million'] \n",
      "\n",
      "Lemmatization:\n",
      " ['the', 'mar', 'orbiter', 'mission', 'mom', 'informally', 'known', 'a', 'mangalyaan', 'wa', 'launched', 'into', 'earth', 'orbit', 'on', 'november', 'by', 'the', 'indian', 'space', 'research', 'organisation', 'isro', 'and', 'ha', 'entered', 'mar', 'orbit', 'on', 'september', 'india', 'thus', 'became', 'the', 'first', 'country', 'to', 'enter', 'mar', 'orbit', 'on', 'it', 'first', 'attempt', 'it', 'wa', 'completed', 'at', 'a', 'record', 'low', 'cost', 'of', 'million'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sentence Tokenization\n",
    "sentences = sent_tokenize(text)\n",
    "print(\"Sentences:\\n\", sentences, \"\\n\")\n",
    "\n",
    "# Word Tokenization\n",
    "words = [w.lower() for w in word_tokenize(text) if w.isalpha()]\n",
    "print(\"Words:\\n\", words, \"\\n\")\n",
    "\n",
    "# Stemming and Lemmatization\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stems = [stemmer.stem(w) for w in words]\n",
    "lemmas = [lemmatizer.lemmatize(w) for w in words]\n",
    "print(\"Stemming:\\n\", stems, \"\\n\")\n",
    "print(\"Lemmatization:\\n\", lemmas, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37d906d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags:\n",
      " [('the', 'DT'), ('mars', 'NNS'), ('orbiter', 'VBP'), ('mission', 'NN'), ('mom', 'NN'), ('informally', 'RB'), ('known', 'VBN'), ('as', 'IN'), ('mangalyaan', 'NN'), ('was', 'VBD'), ('launched', 'VBN'), ('into', 'IN'), ('earth', 'JJ'), ('orbit', 'NN'), ('on', 'IN'), ('november', 'NN'), ('by', 'IN'), ('the', 'DT'), ('indian', 'JJ'), ('space', 'NN'), ('research', 'NN'), ('organisation', 'NN'), ('isro', 'NN'), ('and', 'CC'), ('has', 'VBZ'), ('entered', 'VBN'), ('mars', 'NNS'), ('orbit', 'VBP'), ('on', 'IN'), ('september', 'NN'), ('india', 'JJ'), ('thus', 'RB'), ('became', 'VBD'), ('the', 'DT'), ('first', 'JJ'), ('country', 'NN'), ('to', 'TO'), ('enter', 'VB'), ('mars', 'NNS'), ('orbit', 'RB'), ('on', 'IN'), ('its', 'PRP$'), ('first', 'JJ'), ('attempt', 'NN'), ('it', 'PRP'), ('was', 'VBD'), ('completed', 'VBN'), ('at', 'IN'), ('a', 'DT'), ('record', 'NN'), ('low', 'JJ'), ('cost', 'NN'), ('of', 'IN'), ('million', 'CD')] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# POS Tagging\n",
    "pos_tags = pos_tag(words)\n",
    "print(\"POS Tags:\\n\", pos_tags, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29b05d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: The Mars Orbiter Mission, Label: ORG\n",
      "Entity: Mangalyaan, Label: PERSON\n",
      "Entity: Earth, Label: LOC\n",
      "Entity: 5 November 2013, Label: DATE\n",
      "Entity: the Indian Space Research Organisation, Label: ORG\n",
      "Entity: Mars, Label: LOC\n",
      "Entity: 24 September 2014, Label: DATE\n",
      "Entity: India, Label: GPE\n",
      "Entity: first, Label: ORDINAL\n",
      "Entity: Mars, Label: LOC\n",
      "Entity: first, Label: ORDINAL\n",
      "Entity: $74 million, Label: MONEY\n"
     ]
    }
   ],
   "source": [
    "# Named Entity Recognition\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "# Load the English language model\n",
    "spacy_model = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = spacy_model(text)\n",
    "# Iterate over entities and print their text and label\n",
    "for ent in doc.ents:\n",
    "    print(f\"Entity: {ent.text}, Label: {ent.label_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6bf177a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 'mars'), ('mars', 'orbiter'), ('orbiter', 'mission'), ('mission', 'mom'), ('mom', 'informally'), ('informally', 'known'), ('known', 'as'), ('as', 'mangalyaan'), ('mangalyaan', 'was'), ('was', 'launched'), ('launched', 'into'), ('into', 'earth'), ('earth', 'orbit'), ('orbit', 'on'), ('on', 'november'), ('november', 'by'), ('by', 'the'), ('the', 'indian'), ('indian', 'space'), ('space', 'research'), ('research', 'organisation'), ('organisation', 'isro'), ('isro', 'and'), ('and', 'has'), ('has', 'entered'), ('entered', 'mars'), ('mars', 'orbit'), ('orbit', 'on'), ('on', 'september'), ('september', 'india'), ('india', 'thus'), ('thus', 'became'), ('became', 'the'), ('the', 'first'), ('first', 'country'), ('country', 'to'), ('to', 'enter'), ('enter', 'mars'), ('mars', 'orbit'), ('orbit', 'on'), ('on', 'its'), ('its', 'first'), ('first', 'attempt'), ('attempt', 'it'), ('it', 'was'), ('was', 'completed'), ('completed', 'at'), ('at', 'a'), ('a', 'record'), ('record', 'low'), ('low', 'cost'), ('cost', 'of'), ('of', 'million')]\n",
      "dict_items([(('the', 'mars'), 1), (('mars', 'orbiter'), 1), (('orbiter', 'mission'), 1), (('mission', 'mom'), 1), (('mom', 'informally'), 1), (('informally', 'known'), 1), (('known', 'as'), 1), (('as', 'mangalyaan'), 1), (('mangalyaan', 'was'), 1), (('was', 'launched'), 1), (('launched', 'into'), 1), (('into', 'earth'), 1), (('earth', 'orbit'), 1), (('orbit', 'on'), 3), (('on', 'november'), 1), (('november', 'by'), 1), (('by', 'the'), 1), (('the', 'indian'), 1), (('indian', 'space'), 1), (('space', 'research'), 1), (('research', 'organisation'), 1), (('organisation', 'isro'), 1), (('isro', 'and'), 1), (('and', 'has'), 1), (('has', 'entered'), 1), (('entered', 'mars'), 1), (('mars', 'orbit'), 2), (('on', 'september'), 1), (('september', 'india'), 1), (('india', 'thus'), 1), (('thus', 'became'), 1), (('became', 'the'), 1), (('the', 'first'), 1), (('first', 'country'), 1), (('country', 'to'), 1), (('to', 'enter'), 1), (('enter', 'mars'), 1), (('on', 'its'), 1), (('its', 'first'), 1), (('first', 'attempt'), 1), (('attempt', 'it'), 1), (('it', 'was'), 1), (('was', 'completed'), 1), (('completed', 'at'), 1), (('at', 'a'), 1), (('a', 'record'), 1), (('record', 'low'), 1), (('low', 'cost'), 1), (('cost', 'of'), 1), (('of', 'million'), 1)])\n"
     ]
    }
   ],
   "source": [
    "# Generate bigrams\n",
    "bigrams_list = list(bigrams(words))\n",
    "print(bigrams_list)\n",
    "\n",
    "# Count bigrams\n",
    "bigram_freq = FreqDist(bigrams_list)\n",
    "print(bigram_freq.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80211f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('the', 'mars'): 0.3333333333333333, ('mars', 'orbiter'): 0.3333333333333333, ('orbiter', 'mission'): 1.0, ('mission', 'mom'): 1.0, ('mom', 'informally'): 1.0, ('informally', 'known'): 1.0, ('known', 'as'): 1.0, ('as', 'mangalyaan'): 1.0, ('mangalyaan', 'was'): 1.0, ('was', 'launched'): 0.5, ('launched', 'into'): 1.0, ('into', 'earth'): 1.0, ('earth', 'orbit'): 1.0, ('orbit', 'on'): 1.0, ('on', 'november'): 0.3333333333333333, ('november', 'by'): 1.0, ('by', 'the'): 1.0, ('the', 'indian'): 0.3333333333333333, ('indian', 'space'): 1.0, ('space', 'research'): 1.0, ('research', 'organisation'): 1.0, ('organisation', 'isro'): 1.0, ('isro', 'and'): 1.0, ('and', 'has'): 1.0, ('has', 'entered'): 1.0, ('entered', 'mars'): 1.0, ('mars', 'orbit'): 0.6666666666666666, ('on', 'september'): 0.3333333333333333, ('september', 'india'): 1.0, ('india', 'thus'): 1.0, ('thus', 'became'): 1.0, ('became', 'the'): 1.0, ('the', 'first'): 0.3333333333333333, ('first', 'country'): 0.5, ('country', 'to'): 1.0, ('to', 'enter'): 1.0, ('enter', 'mars'): 1.0, ('on', 'its'): 0.3333333333333333, ('its', 'first'): 1.0, ('first', 'attempt'): 0.5, ('attempt', 'it'): 1.0, ('it', 'was'): 1.0, ('was', 'completed'): 0.5, ('completed', 'at'): 1.0, ('at', 'a'): 1.0, ('a', 'record'): 1.0, ('record', 'low'): 1.0, ('low', 'cost'): 1.0, ('cost', 'of'): 1.0, ('of', 'million'): 1.0}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Count how many times each first word occurs in bigrams\n",
    "first_word_counts = {}\n",
    "for w1, w2 in bigrams_list:\n",
    "    if w1 in first_word_counts:\n",
    "        first_word_counts[w1] += 1\n",
    "    else:\n",
    "        first_word_counts[w1] = 1\n",
    "\n",
    "# Calculate bigram probabilities\n",
    "bigram_prob = {}\n",
    "for (w1, w2), count in bigram_freq.items():\n",
    "    prob = count / first_word_counts[w1]\n",
    "    bigram_prob[(w1, w2)] = prob\n",
    "\n",
    "print(bigram_prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
